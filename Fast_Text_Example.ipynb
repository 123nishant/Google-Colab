{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fast-Text Example.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMjx2dILZOgkzwUtnR+3Zuc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/123nishant/Google-Colab/blob/master/Fast_Text_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6Vh90aNjTot"
      },
      "source": [
        "We will use fastText Library to perform text classification on the dbpedie data which can be downloaded from \n",
        "https://github.com/le-scientifique/torchDatasets/raw/master/dbpedia_csv.tar.gz\n",
        "\n",
        "\n",
        "fastText is a library for learning of \"Word Embeddings\" and \"Text Classification\" created by FB AI Research Lab. \n",
        "\n",
        "This model allows to create an unsupervised learning or supervised learning algorithm for obtaining vector representations for words.\n",
        "\n",
        "FB makes available pretrained models for 294 languages\n",
        "\n",
        "This notebook uses an older version of fastText\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwuEFIORi5s0",
        "outputId": "adc14a2e-098f-44be-c561-abb85d473555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "!pip install fasttext==0.9.2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fasttext==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
            "\r\u001b[K     |████▊                           | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (50.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (1.18.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3018329 sha256=ea451c9fbf6bfa2f3b698d764f15041dddf8e730dae93bc0e25d89274548df83\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l4MCf3OkOsQ"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oDuv-Y7qoGI",
        "outputId": "43f23ea8-bbbc-4a7e-a3c4-dde536c42459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "# downloading the data\n",
        "\n",
        "!wget -P DATAPATH https://github.com/le-scientifique/torchDatasets/raw/master/dbpedia_csv.tar.gz\n",
        "\n",
        "# untaring the required file \n",
        "!tar -xavf DATAPATH/dbpedia_csv.tar.gz -C DATAPATH\n",
        "\n",
        "# sneak peek in the folder structure \n",
        "!ls -lah DATAPATH"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-28 12:24:15--  https://github.com/le-scientifique/torchDatasets/raw/master/dbpedia_csv.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/srhrshr/torchDatasets/raw/master/dbpedia_csv.tar.gz [following]\n",
            "--2020-09-28 12:24:16--  https://github.com/srhrshr/torchDatasets/raw/master/dbpedia_csv.tar.gz\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/srhrshr/torchDatasets/master/dbpedia_csv.tar.gz [following]\n",
            "--2020-09-28 12:24:16--  https://raw.githubusercontent.com/srhrshr/torchDatasets/master/dbpedia_csv.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68431223 (65M) [application/octet-stream]\n",
            "Saving to: ‘DATAPATH/dbpedia_csv.tar.gz’\n",
            "\n",
            "dbpedia_csv.tar.gz  100%[===================>]  65.26M  68.9MB/s    in 0.9s    \n",
            "\n",
            "2020-09-28 12:24:17 (68.9 MB/s) - ‘DATAPATH/dbpedia_csv.tar.gz’ saved [68431223/68431223]\n",
            "\n",
            "dbpedia_csv/\n",
            "dbpedia_csv/test.csv\n",
            "dbpedia_csv/classes.txt\n",
            "dbpedia_csv/train.csv\n",
            "dbpedia_csv/readme.txt\n",
            "total 66M\n",
            "drwxr-xr-x 3 root root 4.0K Sep 28 12:24 .\n",
            "drwxr-xr-x 1 root root 4.0K Sep 28 12:24 ..\n",
            "drwxrwxr-x 2 1000 1000 4.0K Mar 29  2015 dbpedia_csv\n",
            "-rw-r--r-- 1 root root  66M Sep 28 12:24 dbpedia_csv.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XflcH4ZXq68D",
        "outputId": "bf5d3db3-29db-4988-b979-2c32df57ff1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_path = 'DATAPATH'\n",
        "\n",
        "# loading train data\n",
        "train_file = data_path + '/dbpedia_csv/train.csv'\n",
        "df = pd.read_csv(train_file, header = None, names = ['class', 'name', 'description'])\n",
        "\n",
        "# Loading the test data\n",
        "test_file = data_path + '/dbpedia_csv/test.csv'\n",
        "df_test = pd.read_csv(test_file, header = None, names = ['class', 'name', 'description'])\n",
        "\n",
        "# Data we have\n",
        "print(\"Train: {} Test: {}\".format(df.shape, df_test.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: (560000, 3) Test: (70000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhmE0Go2r10Z",
        "outputId": "1ba8e268-98a6-448f-b723-87fb12114f28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Since we have no clue about the classes lets build one\n",
        "# Mapping from class number to class name\n",
        "class_dict = {\n",
        "    1:'Company',\n",
        "    2:'EducationalInstitution',\n",
        "    3:'Artist',\n",
        "    4:'Athlete',\n",
        "    5:'OfficeHolder',\n",
        "    6:'MeanOfTransportation',\n",
        "    7:'Building',\n",
        "    8:'NaturalPlace',\n",
        "    9:'Village',\n",
        "    10:'Animal',\n",
        "    11:'Plant',\n",
        "    12:'Album',\n",
        "    13:'Film',\n",
        "    14:'WrittenWork'\n",
        "}\n",
        "\n",
        "# Mapping the classes \n",
        "df['class_name'] = df['class'].map(class_dict)\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>name</th>\n",
              "      <th>description</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>E. D. Abbott Ltd</td>\n",
              "      <td>Abbott of Farnham E D Abbott Limited was a Br...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Schwan-Stabilo</td>\n",
              "      <td>Schwan-STABILO is a German maker of pens for ...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Q-workshop</td>\n",
              "      <td>Q-workshop is a Polish company located in Poz...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Marvell Software Solutions Israel</td>\n",
              "      <td>Marvell Software Solutions Israel known as RA...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Bergan Mercy Medical Center</td>\n",
              "      <td>Bergan Mercy Medical Center is a hospital loc...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   class  ... class_name\n",
              "0      1  ...    Company\n",
              "1      1  ...    Company\n",
              "2      1  ...    Company\n",
              "3      1  ...    Company\n",
              "4      1  ...    Company\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt6AFkK7uzAh",
        "outputId": "97d1e5b9-0f84-4517-f061-f4fe0e4b70a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>name</th>\n",
              "      <th>description</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>E. D. Abbott Ltd</td>\n",
              "      <td>Abbott of Farnham E D Abbott Limited was a Br...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Schwan-Stabilo</td>\n",
              "      <td>Schwan-STABILO is a German maker of pens for ...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Q-workshop</td>\n",
              "      <td>Q-workshop is a Polish company located in Poz...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Marvell Software Solutions Israel</td>\n",
              "      <td>Marvell Software Solutions Israel known as RA...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Bergan Mercy Medical Center</td>\n",
              "      <td>Bergan Mercy Medical Center is a hospital loc...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559995</th>\n",
              "      <td>14</td>\n",
              "      <td>Barking in Essex</td>\n",
              "      <td>Barking in Essex is a Black comedy play direc...</td>\n",
              "      <td>WrittenWork</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559996</th>\n",
              "      <td>14</td>\n",
              "      <td>Science &amp; Spirit</td>\n",
              "      <td>Science &amp; Spirit is a discontinued American b...</td>\n",
              "      <td>WrittenWork</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559997</th>\n",
              "      <td>14</td>\n",
              "      <td>The Blithedale Romance</td>\n",
              "      <td>The Blithedale Romance (1852) is Nathaniel Ha...</td>\n",
              "      <td>WrittenWork</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559998</th>\n",
              "      <td>14</td>\n",
              "      <td>Razadarit Ayedawbon</td>\n",
              "      <td>Razadarit Ayedawbon (Burmese: ရာဇာဓိရာဇ် အရေး...</td>\n",
              "      <td>WrittenWork</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559999</th>\n",
              "      <td>14</td>\n",
              "      <td>The Vinyl Cafe Notebooks</td>\n",
              "      <td>Vinyl Cafe Notebooks: a collection of essays ...</td>\n",
              "      <td>WrittenWork</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>560000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        class  ...   class_name\n",
              "0           1  ...      Company\n",
              "1           1  ...      Company\n",
              "2           1  ...      Company\n",
              "3           1  ...      Company\n",
              "4           1  ...      Company\n",
              "...       ...  ...          ...\n",
              "559995     14  ...  WrittenWork\n",
              "559996     14  ...  WrittenWork\n",
              "559997     14  ...  WrittenWork\n",
              "559998     14  ...  WrittenWork\n",
              "559999     14  ...  WrittenWork\n",
              "\n",
              "[560000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH7VKbpyu5Fs",
        "outputId": "d7097937-4e74-4a15-a49d-c89174158935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "df['class_name'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NaturalPlace              40000\n",
              "Artist                    40000\n",
              "MeanOfTransportation      40000\n",
              "Building                  40000\n",
              "WrittenWork               40000\n",
              "Village                   40000\n",
              "Company                   40000\n",
              "OfficeHolder              40000\n",
              "Album                     40000\n",
              "Plant                     40000\n",
              "Film                      40000\n",
              "Animal                    40000\n",
              "EducationalInstitution    40000\n",
              "Athlete                   40000\n",
              "Name: class_name, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UotKINtvDS9"
      },
      "source": [
        "# Lets do some cleaning of this text\n",
        "\n",
        "\"\"\"\n",
        "      The normal KD(NFKD) will apply the compatibility decomposition i.e. replace all\n",
        "      compatibility characters with their equivalents. \n",
        "      Normal Form KC (NFKC) 1st applies compatibility decomposition, followed by canonical \n",
        "      decomposition\n",
        "\"\"\"\n",
        "    \n",
        "def clean_it(text,normalize=True):\n",
        "    # Replacing possible issues with data. We can add or reduce the replacemtent in this chain\n",
        "    s = str(text).replace(',',' ').replace('\"','').replace('\\'',' \\' ').replace('.',' . ').replace('(',' ( ').\\\n",
        "            replace(')',' ) ').replace('!',' ! ').replace('?',' ? ').replace(':',' ').replace(';',' ').lower()\n",
        "    \n",
        "    # normalizing / encoding the text\n",
        "    if normalize:\n",
        "   \n",
        "          s = s.normalize('NFKD').str.encode('ascii','ignore').str.decode('utf-8')\n",
        "    \n",
        "    return s\n",
        "\n",
        "# Now lets define a small function where we can use above cleaning on datasets\n",
        "def clean_df(data, cleanit= False, shuffleit=False, encodeit=False, label_prefix='__class__'):\n",
        "    # Defining the new data\n",
        "    df = data[['name','description']].copy(deep=True)\n",
        "    df['class'] = label_prefix + data['class'].astype(str) + ' '\n",
        "    \n",
        "    # cleaning it\n",
        "    if cleanit:\n",
        "        df['name'] = df['name'].apply(lambda x: clean_it(x,encodeit))\n",
        "        df['description'] = df['description'].apply(lambda x: clean_it(x,encodeit))\n",
        "    \n",
        "    # shuffling it\n",
        "    if shuffleit:\n",
        "        df.sample(frac=1).reset_index(drop=True)\n",
        "            \n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "      \n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfByvPwHzl_c",
        "outputId": "17cf5efe-724f-4517-86c5-17112a9d37c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# Transform the datasets using the above clean functions\n",
        "df_train_cleaned = clean_df(df, True, True)\n",
        "df_test_cleaned = clean_df(df_test, True, True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.1 s, sys: 377 ms, total: 6.48 s\n",
            "Wall time: 6.49 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWyL0HnMz_tI"
      },
      "source": [
        "# Write files to disk as fastText Classifier API reads files from disk\n",
        "\n",
        "train_file = data_path + '/dbpedia_train.csv'\n",
        "df_train_cleaned.to_csv(train_file, header = None, index = False, \n",
        "                        columns = ['class', 'name', 'description'])\n",
        "\n",
        "test_file = data_path + '/dbpedia_test.csv'\n",
        "df_test_cleaned.to_csv(test_file, header=None, index=False, \n",
        "                       columns = ['class', 'name', 'description'])\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dsT38fu06O8"
      },
      "source": [
        "Now that we have the train and test files written into disk in a former fastText wants, we are ready to use it for text classification !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnNvikPN0NYB",
        "outputId": "19f28e90-f0d1-49d3-bc05-f9ef0586972b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## using fastText for feature extraction and training\n",
        "from fasttext import train_supervised\n",
        "\"\"\"\n",
        "fastText inputs a training file(csv), a model name as input arguments, \n",
        "label_prefix refers to the prefix before label string in the dataset.\n",
        "\n",
        "default is __label__. \n",
        "In our dataset, it is __class__.\n",
        "\n",
        "There are several other parameters which can be seen in :\n",
        "https://pypi.org/project/fasttext/\n",
        "\"\"\"\n",
        "\n",
        "model = train_supervised(input=train_file, label=\"__class__\", lr=1.0, epoch=75,\n",
        "                         loss='ova', wordNgrams = 2, dim=200, thread=2, verbose=100)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1h 26min 8s, sys: 21.7 s, total: 1h 26min 30s\n",
            "Wall time: 44min 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH2VTBda1-Xj",
        "outputId": "493ee334-b547-4246-bfac-e992c7a11cad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "for k in range(1, 6):\n",
        "\n",
        "  results = model.test(test_file, k=k)\n",
        "  print(f\"Test Samples: {results[0]} Precision@{k} : {results[1]*100:2.4f} Recall@{k} : {results[2]}*100:2.4f\")\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Samples: 70000 Precision@1 : 87.6114 Recall@1 : 0.8761142857142857*100:2.4f\n",
            "Test Samples: 70000 Precision@2 : 46.9550 Recall@2 : 0.9391*100:2.4f\n",
            "Test Samples: 70000 Precision@3 : 31.4710 Recall@3 : 0.9441285714285714*100:2.4f\n",
            "Test Samples: 70000 Precision@4 : 23.8364 Recall@4 : 0.9534571428571429*100:2.4f\n",
            "Test Samples: 70000 Precision@5 : 19.1189 Recall@5 : 0.9559428571428571*100:2.4f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzmodkZC-CJG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0uHoMnAL_nF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}