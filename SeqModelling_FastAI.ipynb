{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeqModelling-FastAI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM6z19WN0MOfKXo0LC9qOzp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/123nishant/Google-Colab/blob/master/SeqModelling_FastAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNW51YTmUilF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9a3b2f6c-bc70-49e3-d9d2-01d5e7a26741"
      },
      "source": [
        "  !curl -s https://course.fast.ai/setup/colab | bash"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BbY8yo3UvY6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "f2517a39-ddae-4e5a-85c4-a1c44779448e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'fastai-v3/'\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGX_WLWHUza2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw4aRHrsU76z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = Config().data_path()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaWflRa9U-v5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "a47945aa-4114-4ec5-f3dd-2147986dba9b"
      },
      "source": [
        "#! wget https://s3.amazonaws.com/fast-ai-nlp/giga-fren.tgz -P {path}"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-12 01:45:32--  https://s3.amazonaws.com/fast-ai-nlp/giga-fren.tgz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.43.134\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.43.134|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2598183296 (2.4G) [application/x-tar]\n",
            "Saving to: ‘/root/.fastai/data/giga-fren.tgz’\n",
            "\n",
            "giga-fren.tgz       100%[===================>]   2.42G  45.0MB/s    in 54s     \n",
            "\n",
            "2020-05-12 01:46:27 (45.6 MB/s) - ‘/root/.fastai/data/giga-fren.tgz’ saved [2598183296/2598183296]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIxXUGDNVFTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! tar xf {path}/giga-fren.tgz -C {path}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTpncXpIVZiW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "705966d0-45f7-4a08-e56c-2b654931acc9"
      },
      "source": [
        "path = Config().data_path()/'giga-fren'\n",
        "path.ls()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/giga-fren/giga-fren.release2.fixed.fr'),\n",
              " PosixPath('/root/.fastai/data/giga-fren/giga-fren.release2.fixed.en')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9ZjbKVwW8pH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with open(path/'giga-fren.release2.fixed.fr') as f: fr = f.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRRrv65or2Da",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TfAbllUW_X3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with open(path/'giga-fren.release2.fixed.en') as f: en = f.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_zEZm2OZNCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
        " re_fq = re.compile('^([^?.!]+\\?)')\n",
        " en_fname = path/'giga-fren.release2.fixed.en'\n",
        " fr_fname = path/'giga-fren.release2.fixed.fr'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZf_SCJ2lzAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " lines = ((re_eq.search(eq), re_fq.search(fq)) \n",
        "         for eq, fq in zip(open(en_fname, encoding='utf-8'), open(fr_fname, encoding='utf-8')))\n",
        " qs = [(e.group(), f.group()) for e,f in lines if e and f]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBkFRQ2Fl2nF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " qs = [(q1,q2) for q1,q2 in qs]\n",
        " df = pd.DataFrame({'fr': [q[1] for q in qs], 'en': [q[0] for q in qs]}, columns = ['en', 'fr'])\n",
        " df.to_csv(path/'questions_easy.csv', index=False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KenWu6PIl7DB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e6ab669b-3d4a-43cb-b9fa-e3f626eafeae"
      },
      "source": [
        "path.ls()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/giga-fren/giga-fren.release2.fixed.fr'),\n",
              " PosixPath('/root/.fastai/data/giga-fren/giga-fren.release2.fixed.en'),\n",
              " PosixPath('/root/.fastai/data/giga-fren/questions_easy.csv')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXgaPw_7sA72",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# **Load our data into a DataBunch**\n",
        "\n",
        "Our questions look like this now:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY2BGh2wr4_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2510f32f-9438-45af-a665-aea8f7e5ba39"
      },
      "source": [
        "df = pd.read_csv(path/'questions_easy.csv')\n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is light ?</td>\n",
              "      <td>Qu’est-ce que la lumière?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who are we?</td>\n",
              "      <td>Où sommes-nous?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Where did we come from?</td>\n",
              "      <td>D'où venons-nous?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What would we do without it?</td>\n",
              "      <td>Que ferions-nous sans elle ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the absolute location (latitude and lo...</td>\n",
              "      <td>Quelle sont les coordonnées (latitude et longi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en                                                 fr\n",
              "0                                    What is light ?                          Qu’est-ce que la lumière?\n",
              "1                                        Who are we?                                    Où sommes-nous?\n",
              "2                            Where did we come from?                                  D'où venons-nous?\n",
              "3                       What would we do without it?                       Que ferions-nous sans elle ?\n",
              "4  What is the absolute location (latitude and lo...  Quelle sont les coordonnées (latitude et longi..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QRnsZT8sJyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['en'] = df['en'].apply(lambda x:x.lower())\n",
        "df['fr'] = df['fr'].apply(lambda x:x.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT5DUqjGsRFx",
        "colab_type": "text"
      },
      "source": [
        "collate inputs and targets in a batch: they have different lengths so we need to add padding to make the sequence length the same;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfcsP7YssNCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_collate(samples, pad_idx=1, pad_first=True, backwards=False):\n",
        "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
        "    samples = to_data(samples)\n",
        "    max_len_x,max_len_y = max([len(s[0]) for s in samples]),max([len(s[1]) for s in samples])\n",
        "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
        "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
        "    if backwards: pad_first = not pad_first\n",
        "    for i,s in enumerate(samples):\n",
        "        if pad_first: \n",
        "            res_x[i,-len(s[0]):],res_y[i,-len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
        "        else:         \n",
        "            res_x[i,:len(s[0]):],res_y[i,:len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
        "    if backwards: res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
        "    return res_x,res_y\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRlr1vb-saAO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "764ba552-d4e6-4da3-e312-083cccb40c6a"
      },
      "source": [
        "doc(Dataset)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h2 id=\"Dataset\" class=\"doc_header\"><code>class</code> <code>Dataset</code><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#Dataset-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h2><blockquote><p><code>Dataset</code>()</p>\n",
              "</blockquote>\n",
              "<div class=\"collapse\" id=\"Dataset-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#Dataset-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>Dataset</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div><p>An abstract class representing a :class:<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\"><code>Dataset</code></a>. All datasets that represent a map from keys to data samples should subclass\n",
              "it. All subclasses should overwrite :meth:<code>__getitem__</code>, supporting fetching a\n",
              "data sample for a given key. Subclasses could also optionally overwrite\n",
              ":meth:<code>__len__</code>, which is expected to return the size of the dataset by many\n",
              ":class:<code>~torch.utils.data.Sampler</code> implementations and the default options\n",
              "of :class:<code>~torch.utils.data.DataLoader</code>.</p>\n",
              "<p>.. note::\n",
              "  :class:<code>~torch.utils.data.DataLoader</code> by default constructs a index\n",
              "  sampler that yields integral indices.  To make it work with a map-style\n",
              "  dataset with non-integral indices/keys, a custom sampler must be provided.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4oGMyt3sche",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "fbbdc08c-9472-40af-af4a-bd648c692df6"
      },
      "source": [
        "doc(DataLoader)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h2 id=\"DataLoader\" class=\"doc_header\"><code>class</code> <code>DataLoader</code><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#DataLoader-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h2><blockquote><p><code>DataLoader</code>(<strong><code>dataset</code></strong>, <strong><code>batch_size</code></strong>=<strong><em><code>1</code></em></strong>, <strong><code>shuffle</code></strong>=<strong><em><code>False</code></em></strong>, <strong><code>sampler</code></strong>=<strong><em><code>None</code></em></strong>, <strong><code>batch_sampler</code></strong>=<strong><em><code>None</code></em></strong>, <strong><code>num_workers</code></strong>=<strong><em><code>0</code></em></strong>, <strong><code>collate_fn</code></strong>=<strong><em><code>'default_collate'</code></em></strong>, <strong><code>pin_memory</code></strong>=<strong><em><code>True</code></em></strong>, <strong><code>drop_last</code></strong>=<strong><em><code>False</code></em></strong>, <strong><code>timeout</code></strong>=<strong><em><code>0</code></em></strong>, <strong><code>worker_init_fn</code></strong>=<strong><em><code>None</code></em></strong>)</p>\n",
              "</blockquote>\n",
              "<div class=\"collapse\" id=\"DataLoader-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#DataLoader-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>DataLoader</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div><p>Data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset.</p>\n",
              "<p>The :class:<code>~torch.utils.data.DataLoader</code> supports both map-style and\n",
              "iterable-style datasets with single- or multi-process loading, customizing\n",
              "loading order and optional automatic batching (collation) and memory pinning.</p>\n",
              "<p>See :py:mod:<a href=\"https://pytorch.org/docs/stable/data.html#module-torch.utils.data\"><code>torch.utils.data</code></a> documentation page for more details.</p>\n",
              "<p>Arguments:\n",
              "    dataset (Dataset): dataset from which to load the data.\n",
              "    batch_size (int, optional): how many samples per batch to load\n",
              "        (default: <code>1</code>).\n",
              "    shuffle (bool, optional): set to <code>True</code> to have the data reshuffled\n",
              "        at every epoch (default: <code>False</code>).\n",
              "    sampler (Sampler, optional): defines the strategy to draw samples from\n",
              "        the dataset. If specified, :attr:<code>shuffle</code> must be <code>False</code>.\n",
              "    batch_sampler (Sampler, optional): like :attr:<code>sampler</code>, but returns a batch of\n",
              "        indices at a time. Mutually exclusive with :attr:<code>batch_size</code>,\n",
              "        :attr:<code>shuffle</code>, :attr:<code>sampler</code>, and :attr:<code>drop_last</code>.\n",
              "    num_workers (int, optional): how many subprocesses to use for data\n",
              "        loading. <code>0</code> means that the data will be loaded in the main process.\n",
              "        (default: <code>0</code>)\n",
              "    collate_fn (callable, optional): merges a list of samples to form a\n",
              "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
              "        map-style dataset.\n",
              "    pin_memory (bool, optional): If <code>True</code>, the data loader will copy Tensors\n",
              "        into CUDA pinned memory before returning them.  If your data elements\n",
              "        are a custom type, or your :attr:<code>collate_fn</code> returns a batch that is a custom type,\n",
              "        see the example below.\n",
              "    drop_last (bool, optional): set to <code>True</code> to drop the last incomplete batch,\n",
              "        if the dataset size is not divisible by the batch size. If <code>False</code> and\n",
              "        the size of dataset is not divisible by the batch size, then the last batch\n",
              "        will be smaller. (default: <code>False</code>)\n",
              "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
              "        from workers. Should always be non-negative. (default: <code>0</code>)\n",
              "    worker_init_fn (callable, optional): If not <code>None</code>, this will be called on each\n",
              "        worker subprocess with the worker id (an int in <code>[0, num_workers - 1]</code>) as\n",
              "        input, after seeding and before data loading. (default: <code>None</code>)</p>\n",
              "<p>.. warning:: If the <code>spawn</code> start method is used, :attr:<code>worker_init_fn</code>\n",
              "             cannot be an unpicklable object, e.g., a lambda function. See\n",
              "             :ref:<code>multiprocessing-best-practices</code> on more details related\n",
              "             to multiprocessing in PyTorch.</p>\n",
              "<p>.. note:: <code>len(dataloader)</code> heuristic is based on the length of the sampler used.\n",
              "          When :attr:<code>dataset</code> is an :class:<code>~torch.utils.data.IterableDataset</code>,\n",
              "          <code>len(dataset)</code> (if implemented) is returned instead, regardless\n",
              "          of multi-process loading configurations, because PyTorch trust\n",
              "          user :attr:<code>dataset</code> code in correctly handling multi-process\n",
              "          loading to avoid duplicate data. See <code>Dataset Types</code><em> for more\n",
              "          details on these two types of datasets and how\n",
              "          :class:<code>~torch.utils.data.IterableDataset</code> interacts with <code>Multi-process data loading</code></em>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mdJcv_-sh_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "8a74acf0-c7b5-42b8-baec-690b0dce85f7"
      },
      "source": [
        "\n",
        "\n",
        "doc(DataBunch)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h2 id=\"DataBunch\" class=\"doc_header\"><code>class</code> <code>DataBunch</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/basic_data.py#L84\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#DataBunch-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h2><blockquote><p><code>DataBunch</code>(<strong><code>train_dl</code></strong>:<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\"><code>DataLoader</code></a>, <strong><code>valid_dl</code></strong>:<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\"><code>DataLoader</code></a>, <strong><code>fix_dl</code></strong>:<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\"><code>DataLoader</code></a>=<strong><em><code>None</code></em></strong>, <strong><code>test_dl</code></strong>:<code>Optional</code>[<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\"><code>DataLoader</code></a>]=<strong><em><code>None</code></em></strong>, <strong><code>device</code></strong>:<a href=\"https://pytorch.org/docs/stable/tensor_attributes.html#torch-device\"><code>device</code></a>=<strong><em><code>None</code></em></strong>, <strong><code>dl_tfms</code></strong>:<code>Optional</code>[<code>Collection</code>[<code>Callable</code>]]=<strong><em><code>None</code></em></strong>, <strong><code>path</code></strong>:<code>PathOrStr</code>=<strong><em><code>'.'</code></em></strong>, <strong><code>collate_fn</code></strong>:<code>Callable</code>=<strong><em><code>'data_collate'</code></em></strong>, <strong><code>no_check</code></strong>:<code>bool</code>=<strong><em><code>False</code></em></strong>)</p>\n",
              "</blockquote>\n",
              "<div class=\"collapse\" id=\"DataBunch-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#DataBunch-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>Tests found for <code>DataBunch</code>:</p><ul><li><code>pytest -sv tests/test_data_block.py::test_custom_dataset</code> <a href=\"https://github.com/fastai/fastai/blob/master/tests/test_data_block.py#L152\" class=\"source_link\" style=\"float:right\">[source]</a></li></ul><p>To run tests please refer to this <a href=\"/dev/test.html#quick-guide\">guide</a>.</p></div></div><p>Bind <code>train_dl</code>,<code>valid_dl</code> and <code>test_dl</code> in a data object.</p>\n",
              "<p><a href=\"https://docs.fast.ai/basic_data.html#DataBunch\" target=\"_blank\" rel=\"noreferrer noopener\">Show in docs</a></p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv_H3polskkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}