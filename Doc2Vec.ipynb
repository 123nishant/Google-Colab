{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Doc2Vec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMNns+YuegzCIW7MPk6W49g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/123nishant/Google-Colab/blob/master/Doc2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycwL7nWN-2h7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "76d42eea-8a10-4e4d-d160-33dc40f50f10"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jz5iTPg_6gf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "a3b7f3db-9d4f-45ca-c387-40328dbbc47f"
      },
      "source": [
        "# Downloading data\n",
        "!wget -P DATAPATH https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch4/Data/Sentiment%20and%20Emotion%20in%20Text/train_data.csv\n",
        "!wget -P DATAPATH https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch4/Data/Sentiment%20and%20Emotion%20in%20Text/test_data.csv\n",
        "!ls -lah DATAPATH"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-25 06:43:58--  https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch4/Data/Sentiment%20and%20Emotion%20in%20Text/train_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2479133 (2.4M) [text/plain]\n",
            "Saving to: ‘DATAPATH/train_data.csv’\n",
            "\n",
            "train_data.csv      100%[===================>]   2.36M  10.1MB/s    in 0.2s    \n",
            "\n",
            "2020-09-25 06:43:59 (10.1 MB/s) - ‘DATAPATH/train_data.csv’ saved [2479133/2479133]\n",
            "\n",
            "--2020-09-25 06:43:59--  https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch4/Data/Sentiment%20and%20Emotion%20in%20Text/test_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 783640 (765K) [text/plain]\n",
            "Saving to: ‘DATAPATH/test_data.csv’\n",
            "\n",
            "test_data.csv       100%[===================>] 765.27K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-09-25 06:43:59 (7.01 MB/s) - ‘DATAPATH/test_data.csv’ saved [783640/783640]\n",
            "\n",
            "total 3.2M\n",
            "drwxr-xr-x 2 root root 4.0K Sep 25 06:43 .\n",
            "drwxr-xr-x 1 root root 4.0K Sep 25 06:43 ..\n",
            "-rw-r--r-- 1 root root 766K Sep 25 06:43 test_data.csv\n",
            "-rw-r--r-- 1 root root 2.4M Sep 25 06:43 train_data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6zx3cW0AM1g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "6641496d-a2ce-4d1c-858b-b5fd2cd28fdf"
      },
      "source": [
        "#Load the dataset and explore.\n",
        "filepath = \"DATAPATH/train_data.csv\"\n",
        "df = pd.read_csv(filepath)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentiment                                            content\n",
              "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
              "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2     sadness                Funeral ceremony...gloomy friday...\n",
              "3  enthusiasm               wants to hang out with friends SOON!\n",
              "4     neutral  @dannycastillo We want to trade with someone w..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB2RbaEqAeku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "06559c49-d80c-4910-e07f-06819c7d1b17"
      },
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "worry         7433\n",
              "neutral       6340\n",
              "sadness       4828\n",
              "happiness     2986\n",
              "love          2068\n",
              "surprise      1613\n",
              "hate          1187\n",
              "fun           1088\n",
              "relief        1021\n",
              "empty          659\n",
              "enthusiasm     522\n",
              "boredom        157\n",
              "anger           98\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFQVHpR8Ajw-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd774e87-f3f9-4eb0-bff7-904858d791ca"
      },
      "source": [
        "# Let us take the 3 categories and leave out the rest\n",
        "shortlist = ['neutral', 'happiness', 'worry']\n",
        "df_subset = df[df['sentiment'].isin(shortlist)]\n",
        "df_subset.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16759, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f93xFzuwA3m2",
        "colab_type": "text"
      },
      "source": [
        "# Text Pre-Processing\n",
        "\n",
        "1. Removing @mentions, and urls\n",
        "2. Using NLTK Tweet tokenizer instead of regular one\n",
        "3. Stopwords, numbers as usual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFrTHpIEA2eP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1e6dee5-6c46-4e6d-fb6c-7a7ae8c50684"
      },
      "source": [
        "# strip_handles removes personal information such as twitter handles, which don't\n",
        "# contribute to emotion in the tweet. \n",
        "# preserve_case=False converts everything to lowercase\n",
        "\n",
        "tweeter = TweetTokenizer(strip_handles=True, preserve_case = False)\n",
        "mystopwords = set(stopwords.words(\"english\"))\n",
        "\n",
        "#Function to tokenize tweets, remove stopwords and numbers.\n",
        "# Keeping punctuations and emoticon symbols could be relevant for this task !\n",
        "\n",
        "def preprocess_corpus(texts):\n",
        "  \n",
        "  def remove_stop_digits(tokens):\n",
        "    # Nested function that removes stopwords and digits froma list of tokens\n",
        "    return [token for token in tokens if token not in mystopwords and not token.isdigit()]\n",
        "\n",
        "  # This Return statement below uses the above function to process twitter tokenizer output further\n",
        "  return [remove_stop_digits(tweeter.tokenize(content)) for content in texts]\n",
        "\n",
        "# df_subset contains only 3 categories we chose\n",
        "mydata = preprocess_corpus(df_subset['content'])\n",
        "mycats = df_subset['sentiment']\n",
        "print(len(mydata), len(mycats))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16759 16759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kLTwUhBCs6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c26e75a1-77ac-4a85-cee5-f6b6f46439e1"
      },
      "source": [
        "# Split data into train and test, following the usual process\n",
        "train_data, test_data, train_cats, test_cats = train_test_split(mydata, mycats, random_state=1234)\n",
        "\n",
        "# Prepare training data in doc2vec format : \n",
        "train_doc2vec = [TaggedDocument((d), tags = [str(i)]) for i, d in enumerate(train_data)]\n",
        "\n",
        "# Train a doc2vec model to learn tweet representations. Use only training data !!\n",
        "model = Doc2Vec(vector_size = 50, alpha =0.025, min_count = 5, dm=1, epochs=100)\n",
        "\n",
        "model.build_vocab(train_doc2vec)\n",
        "\n",
        "model.train(train_doc2vec, total_examples = model.corpus_count, epochs = model.epochs)\n",
        "\n",
        "model.save(\"d2v.model\")\n",
        "print(\"Model Saved\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Saved\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHI457tSEEfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "8ff14a87-3f72-489d-e7c8-fcc55e2bc771"
      },
      "source": [
        "# Infer the feature reprsentation for training and test data using the trained model \n",
        "\n",
        "model = Doc2Vec.load(\"d2v.model\")\n",
        "# Infer in  multiple steps to get a stable representation\n",
        "train_vectors = [model.infer_vector(list_of_tokens, steps = 50) for list_of_tokens in train_data]\n",
        "test_vectors = [model.infer_vector(list_of_tokens, steps = 50) for list_of_tokens in test_data]\n",
        "\n",
        "# Use any regular classifier like Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "myclass = LogisticRegression(class_weight = \"balanced\")  # Because classes are not balanced\n",
        "myclass.fit(train_vectors, train_cats)\n",
        "\n",
        "preds = myclass.predict(test_vectors)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(test_cats, preds))\n",
        "\n",
        "# print(confusion_matrix(test_cats, preds))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   happiness       0.34      0.53      0.41       713\n",
            "     neutral       0.46      0.54      0.50      1595\n",
            "       worry       0.60      0.39      0.47      1882\n",
            "\n",
            "    accuracy                           0.47      4190\n",
            "   macro avg       0.47      0.49      0.46      4190\n",
            "weighted avg       0.50      0.47      0.47      4190\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymw90KJrGXBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}